"""Custom dataset for malware analysis JSONL format."""
import json
from torch.utils.data import Dataset


class MalwareAnalysisDataset(Dataset):
    def __init__(self, path_or_dataset, tokenizer, split="train", max_length=2048):
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.samples = []
        with open(path_or_dataset, "r") as f:
            for line in f:
                self.samples.append(json.loads(line.strip()))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        record = self.samples[idx]
        conversations = record["conversations"]
        system_msg = conversations[0]["content"]
        user_msg = conversations[1]["content"]
        assistant_msg = conversations[2]["content"]

        if "<binary>" in user_msg and "</binary>" in user_msg:
            start = user_msg.index("<binary>") + len("<binary>")
            end = user_msg.index("</binary>")
            binary_hex = user_msg[start:end]
            question = user_msg[end + len("</binary>"):]
            reserved_chars = (self.max_length - 200) * 2
            if len(binary_hex) > reserved_chars:
                binary_hex = binary_hex[:reserved_chars]
            user_msg = "<binary>" + binary_hex + "</binary>" + question

        full_text = (
            "<|system|>\n" + system_msg + "\n"
            + "<|user|>\n" + user_msg + "\n"
            + "<|assistant|>\n" + assistant_msg + "<|endoftext|>"
        )

        # Return plain lists - the default_collater handles padding and tensors
        encoding = self.tokenizer(
            full_text,
            max_length=self.max_length,
            truncation=True,
        )

        input_ids = encoding["input_ids"]
        labels = list(input_ids)

        return {
            "input_ids": input_ids,
            "labels": labels,
        }
